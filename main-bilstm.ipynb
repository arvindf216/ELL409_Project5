{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, LayerNormalization, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "# !pip install gensim  # uncommnet to install\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('/kaggle/input/nlpword2vecembeddingspretrained/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# the poems from gutenburg website were copied and pasted to poems.txt\n",
    "import re\n",
    "\n",
    "corpus = []\n",
    "with open('/kaggle/input/poems-frost/poems.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip('\\n')\n",
    "        #skip empty lines, chapter numbers, poem headings (in capitals)\n",
    "        if not line or line in [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\"] or line.isupper():\n",
    "            continue\n",
    "        punctuation = '!\"#$%&\\'()*+/:;<=>?@[\\\\]^_`{|}~'\n",
    "        # Clean the line and add it to the current poem\n",
    "        #cleaned_line = line.lower().strip(punctuation).replace('.', ' ').replace(',', ' ').replace('-', ' ').replace('—', ' ').replace('?', ' ').replace(' \\' ', ' ').replace('!','').replace('\\\"','').replace(':','').replace(';','')\n",
    "        cleaned_line = line.lower().strip(punctuation).replace('-', ' ').replace('—', ' ').replace(' \\' ', ' ').replace('\\\"','').replace(':','').replace(';','')\n",
    "        corpus.append(cleaned_line)\n",
    "\n",
    "# Join all poems into a single text\n",
    "text = ' '.join(corpus)\n",
    "text = re.sub(r'\\s+', ' ', text)\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize words and create vocabulary\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1  # Including padding token (token number 0)\n",
    "print(\"Total words in vocabulary:\", total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preparing the embedding matrix\n",
    "embedding_dim = word2vec.vector_size\n",
    "embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec:\n",
    "        embedding_matrix[i] = word2vec[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 50  # Adjust this as needed\n",
    "input_sequences = []\n",
    "token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "for i in range(1, len(token_list)):\n",
    "    n_gram_sequence = token_list[max(0, i - max_seq_len):i+1]\n",
    "    input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences to create uniform input length\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre'))\n",
    "\n",
    "print(input_sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split sequences into input and output\n",
    "X = input_sequences[:,:-1]  # all except last word\n",
    "y = input_sequences[:,-1]    # last word is the target\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate perplexity\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = tf.exp(tf.reduce_mean(cross_entropy))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(max_seq_len,)),\n",
    "    Embedding(input_dim=total_words,\n",
    "              output_dim=embedding_dim,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False),  # Freeze embeddings\n",
    "    Bidirectional(LSTM(units=128, return_sequences=True)), \n",
    "        # kernel_regularizer=l2(1e-4),  # L2 regularization\n",
    "        # recurrent_regularizer=l2(1e-4)),\n",
    "    Dropout(rate=0.3),\n",
    "    BatchNormalization(),\n",
    "    # LayerNormalization(),\n",
    "    LSTM(units=64), \n",
    "        # kernel_regularizer=l2(1e-4), \n",
    "        # recurrent_regularizer=l2(1e-4)),\n",
    "    # Dropout(rate=0.3),\n",
    "    # LayerNormalization(),\n",
    "    Dense(units=total_words, activation='softmax'),\n",
    "          # kernel_regularizer=l2(1e-4))  # L2 regularization\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# lr_schedule = ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.95,\n",
    "#     staircase=True)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=5e-3)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', perplexity])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "\n",
    "# can add early stopping criterion to reduce overfitting\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Perplexity\n",
    "test_perplexity = perplexity(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {results[1] * 100:.2f}%\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words=20):\n",
    "    print(seed_text, end = ' ')\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "        prediction_output = model.predict(token_list, verbose=0)\n",
    "        predicted = np.argmax(prediction_output, axis=-1)[0]\n",
    "        output_word = tokenizer.index_word[predicted]\n",
    "        seed_text += \" \" + output_word\n",
    "        print(output_word, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate text with the model\n",
    "seed_text = \"deep down the\"  # change seed text as per requirement\n",
    "generate_text(seed_text, next_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed_text = \"I wish\"  # change seed text as per requirement\n",
    "generate_text(seed_text, next_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed_text = \"The woods are\"  # change seed text as per requirement\n",
    "generate_text(seed_text, next_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed_text = \"Once upon\"  # change seed text as per requirement\n",
    "generate_text(seed_text, next_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed_text = \"The sun sets\"  # change seed text as per requirement\n",
    "generate_text(seed_text, next_words=100)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 11594,
     "sourceId": 16023,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6118426,
     "sourceId": 9949405,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6121076,
     "sourceId": 9952945,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
